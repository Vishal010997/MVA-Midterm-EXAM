---
title: "Social Media MVA"
output: html_document
date: "2024-03-29"
---


```{R}
library(readxl)
social_media <- read_excel("C:/Users/Vishal/Downloads/MVA_CLASS_COMBINE.xlsx")
str(social_media)
social_media_cleaned <- social_media[,-1]
```
```{r}
#changing column names
change_cols_index <- c(2,4,6,8,10,12,14,16,17,18,19,20,21,22,23,24)
change_cols_name <- c("Instagram_Time", "Linkedin_Time", "Snapchat_Time", "Twitter_Time", "Whatsapp_Time", "Youtube_Time", "OTT_Time", "Reddit_Time", "Application Type", "Interview_call_received", "Networking", "Learning", "Mood_Productivity", "Morning_tireness", "Sleep_trouble", "Weekly_Feelings")

colnames(social_media_cleaned)[change_cols_index] <- change_cols_name


social_media_cleaned

```



```{R}
# Convert "NA", "N/A", "n/a", "na", "N.A", "n.a" to 0
social_media_cleaned[social_media_cleaned == "NA" | social_media_cleaned == "N/A" | social_media_cleaned == "na" | social_media_cleaned == "n/a" | social_media_cleaned == "N.A" | social_media_cleaned == "n.a" | social_media_cleaned == "0" | social_media_cleaned == ""] <- NA
social_media_cleaned
```
```{r}
social_media_cleaned[is.na(social_media_cleaned)] <- '0'
social_media_cleaned
```
```{r}
# Define a function to convert time strings to decimal hours
convert_to_decimal_hours <- function(time_string) {
# Check if NA values are present
if (any(is.na(time_string))) {
         return(rep(NA, length(time_string)))  # Return NA for NA values
     }
     
# Define a function to convert HH:MM format to decimal hours
     hhmm_to_decimal <- function(hhmm) {
         parts <- as.numeric(strsplit(hhmm, ":")[[1]])  # Split into hours and minutes
         hours <- parts[1]
         minutes <- ifelse(length(parts) > 1, parts[2], 0)  # Handle missing minutes
         total_hours <- hours + minutes / 60
         return(total_hours)
     }
     
# Convert time strings to decimal hours
decimal_hours <- sapply(time_string, function(x) {
         if (grepl("^\\d+:\\d+$", x)) {
             return(hhmm_to_decimal(x))  # Convert HH:MM format
         } else if (grepl("^\\d+\\.\\d+$", x)) {
             return(as.numeric(x))  # Convert decimal format
         } else if (grepl("^\\d+$", x)) {
             return(as.numeric(x))  # Convert whole numbers
         } else {
             return(NA)  # Return NA for other cases
         }
     })
     
     return(decimal_hours)
}

time_columns <- c("Instagram_Time", "Linkedin_Time", "Snapchat_Time", "Twitter_Time", "Whatsapp_Time", "Youtube_Time", "OTT_Time", "Reddit_Time") 
# Apply the conversion function to all time columns
social_media_cleaned[time_columns] <- lapply(social_media_cleaned[time_columns], convert_to_decimal_hours)
 
# Verify the result
str(social_media_cleaned)

#Dropping the name columns
social_media_cleaned <- social_media_cleaned[, -c(1, 3, 5, 7, 9, 11, 13, 15)] 
social_media_cleaned
```
```{r}
#Treating NA in whatsapp column
mean_value <- mean(social_media_cleaned$Whatsapp_Time, na.rm = TRUE)
social_media_cleaned$Whatsapp_Time[is.na(social_media_cleaned$Whatsapp_Time)] <- mean_value

social_media_cleaned
```
```{r}
#Scaling the data
# Extracting the columns with names ending in "_Time"
time_columns <- grep("_Time$", names(social_media_cleaned), value = TRUE)

# Scaling the time columns
scaled_time_data <- scale(social_media_cleaned[time_columns])

#plotting the scaled values
x_time_columns <- grep("_Time$", names(social_media_cleaned), value = TRUE)
x_time_columns
```
```{R}
# Plot histograms for each x_time column
par(mfrow = c(2, 3))

# Adjust the layout based on the number of x_time columns
for (col in x_time_columns) {
    hist(scaled_time_data, main = col, xlab = "Scaled Value")
}
```
```{r}
scaled_time_data
```
```{R}
#Performing PCA

# Compute the covariance matrix
cov_matrix <- cov(scaled_time_data)
cov_matrix
```
```{R}
# Perform eigenvalue decomposition
eigen_result <- eigen(cov_matrix)
eigen_result
```
```{r}

# Extract eigenvalues and eigenvectors
eigenvalues <- eigen_result$values
eigenvalues
```
```{r}
eigenvectors <- eigen_result$vectors
eigenvectors
```
```{R}
#To find number of principal components to consider:
#1 Eigenvalue criterion
eigenvalues <- eigen_result$values
num_components <- sum(eigenvalues > 1)
print(num_components)
```
```{R}
#2 Scree plot
plot(eigenvalues, type = "b", main = "Scree Plot")
abline(h = 1, col = "red", lty = 2)
```
```{R}
#Retaining 3 PC
n_components <- 3  
transformed_data <- scaled_time_data %*% eigenvectors[, 1:n_components]
print(transformed_data)
```



```{r}
library(RColorBrewer)
loadings <- eigenvectors[, 1:n_components]
my_palette <- colorRampPalette(brewer.pal(9, "YlOrRd")) 
# Visualize the loadings matrix with the specified color palette
heatmap(loadings, Rowv = NA, Colv = NA, col = my_palette(256), scale = "column", margins = c(5, 10))
```
```{R}
# Scatter plot of the first two principal components
plot(transformed_data[, 3], transformed_data[, 1], xlab = "PC1", ylab = "PC2", 
     main = "Scatter Plot of PC1 vs PC2")

biplot(prcomp(scaled_time_data), scale = 0)
```
```{r}
# Cumulative Variance Plot
cumulative_variance <- cumsum(eigenvalues) / sum(eigenvalues)
plot(1:length(cumulative_variance), cumulative_variance, type = "b", 
     xlab = "Number of Principal Components", ylab = "Cumulative Variance Explained",
     main = "Cumulative Variance Plot")
```
```{R}
# 3D Scatter Plot
library(scatterplot3d)
scatterplot3d(transformed_data[, 1], transformed_data[, 2], transformed_data[, 3],
              xlab = "PC1", ylab = "PC2", zlab = "PC3",
              main = "3D Scatter Plot of PC1, PC2, and PC3")
```
```{R}
# Heatmap of Correlation Matrix
corr_matrix <- cor(scaled_time_data)
heatmap(corr_matrix, Rowv = NA, Colv = NA, col = heat.colors(256))
```


```{R}
#Cluster Analysis

# Define the maximum number of clusters to test
max_k <- 10

# Perform K-means clustering for different values of k
wcss <- numeric(length = max_k)
for (i in 1:max_k) {
  kmeans_model <- kmeans(scaled_time_data, centers = i)
  wcss[i] <- kmeans_model$tot.withinss
}
```
```{R}
# Plot the elbow method
plot(1:max_k, wcss, type = "b", xlab = "Number of clusters (k)", ylab = "Within-cluster sum of squares (WCSS)")
```
```{R}
# Step 1: Choose the number of clusters (K)
K <- 6 
# Step 2: Perform K-means clustering
kmeans_result <- kmeans(scaled_time_data, centers = K)
# Step 3: View cluster centers
print(kmeans_result$centers)
# Step 4: View cluster assignments for each data point
print(kmeans_result$cluster)
```
```{r}
# Computing the percentage of variation accounted for. Two clusters
(kmeans2.sm <- kmeans(scaled_time_data,2,nstart = 10))
perc.var.2 <- round(100*(1 - kmeans2.sm$betweenss/kmeans2.sm$totss),1)
names(perc.var.2) <- "Perc. 2 clus"
perc.var.2
```
```{R}
# Computing the percentage of variation accounted for. Three clusters
(kmeans3.sm <- kmeans(scaled_time_data,3,nstart = 10))
perc.var.3 <- round(100*(1 - kmeans3.sm$betweenss/kmeans2.sm$totss),1)
names(perc.var.3) <- "Perc. 3 clus"
perc.var.3
```
```{r}
# Computing the percentage of variation accounted for. Four clusters
(kmeans4.sm <- kmeans(scaled_time_data,4,nstart = 10))
perc.var.4 <- round(100*(1 - kmeans4.sm$betweenss/kmeans4.sm$totss),1)
names(perc.var.4) <- "Perc. 4 clus"
perc.var.4
```
```{r}
# Computing the percentage of variation accounted for. Five clusters
(kmeans5.sm <- kmeans(scaled_time_data,5,nstart = 10))
perc.var.5 <- round(100*(1 - kmeans5.sm$betweenss/kmeans5.sm$totss),1)
names(perc.var.5) <- "Perc. 5 clus"
perc.var.5
```
```{R}
# Computing the percentage of variation accounted for. Six clusters
(kmeans6.sm <- kmeans(scaled_time_data,6,nstart = 10))
perc.var.6 <- round(100*(1 - kmeans6.sm$betweenss/kmeans6.sm$totss),1)
names(perc.var.6) <- "Perc. 6 clus"
perc.var.6
```
```{R}
attributes(perc.var.6)
```
```{r}
Variance_List <- c(perc.var.2,perc.var.3,perc.var.4,perc.var.5,perc.var.6)

Variance_List
plot(Variance_List)
```
```{R}
#elbow method
# Perform K-means clustering for different numbers of clusters
wss <- numeric(length = 5)

for (k in 2:6) {
  kmeans_model <- kmeans(scaled_time_data, k, nstart = 10)
  wss[k - 1] <- kmeans_model$tot.withinss
}

#elbow curve
plot(2:6, wss, type = "b", xlab = "Number of Clusters", ylab = "Within-cluster Sum of Squares", main = "Elbow Method")
```
```{r}
#silhouette method

library(cluster)

sil_width <- numeric(length = 5)

# Computing silhouette widths for different numbers of clusters
for (k in 2:6) {
  # Perform K-means clustering
  kmeans_model <- kmeans(scaled_time_data, k, nstart = 10)
  
  if (k > 1) {  # Silhouette width using two clusters
    silhouette_width <- silhouette(kmeans_model$cluster, dist(scaled_time_data))
    sil_width[k - 1] <- mean(silhouette_width[, "sil_width"])
  }
}

# Plot the silhouette scores
plot(2:6, sil_width, type = "b")
```
```{r}
#2. Show the membership for each cluster
optimal_num_clusters <- 5

#K-means clustering with the optimal number of clusters
kmeans_model <- kmeans(scaled_time_data, optimal_num_clusters, nstart = 10)

cluster_membership <- kmeans_model$cluster

# Print the cluster membership for each data point
print(cluster_membership)
```
```{R}
# Scatter plot of the data with clusters colored by membership
plot(scaled_time_data[, 1], scaled_time_data[, 2], 
     col = kmeans_model$cluster, pch = 16, 
     xlab = "Variable 1", ylab = "Variable 2",
     main = "K-means Clustering")

# Adding cluster centers to the plot
points(kmeans_model$centers[, 1], kmeans_model$centers[, 2], col = 1:optimal_num_clusters, pch = 3, cex = 2)

# Adding legend
legend("topright", legend = paste("Cluster", 1:optimal_num_clusters), col = 1:optimal_num_clusters, pch = 16, cex = 1.2, title = "Clusters")
```
```{R}
#3. Show a visualization of the cluster and membership using the first two Principal Components.

# Perform PCA
pca_result <- prcomp(scaled_time_data, scale. = TRUE)

# Extract PC scores for the first three principal components
PC1 <- pca_result$x[, 1]
PC2 <- pca_result$x[, 2]
PC3 <- pca_result$x[, 3]

# Plot the data with clusters colored by membership
plot(PC1, PC2, 
     col = kmeans_model$cluster, pch = 16, 
     xlab = "Principal Component 1", ylab = "Principal Component 2",
     main = "K-means Clustering based on PC1 and PC2")

# Add legend
legend("topright", legend = paste("Cluster", 1:optimal_num_clusters), 
       col = 1:optimal_num_clusters, pch = 16, cex = 1.2, title = "Clusters")
```
```{r}
# Saving five k-means clusters in a list
# Initialize a list to store matrices for each cluster
cluster_matrices <- list()
 
# Iterate over each cluster
for (i in 1:max(kmeans5.sm$cluster)) {
     # Subset data for the current cluster
     cluster_indices <- which(kmeans5.sm$cluster == i)
     cluster_data <- scaled_time_data[cluster_indices, ]
     
     # Store the cluster data in the list
     cluster_matrices[[paste0("clus", i)]] <- cluster_data
 }
 
# Check the list of matrices
print(cluster_matrices)
```


```{R}

```  